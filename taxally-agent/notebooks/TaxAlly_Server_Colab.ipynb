{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üßæ TaxAlly API Server (Colab ‚Üí Webapp)\n",
        "\n",
        "This notebook runs the TaxAlly HuggingFace server on Colab and exposes it via ngrok.\n",
        "\n",
        "Your webapp can then connect to it!\n",
        "\n",
        "## Setup\n",
        "1. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\n",
        "2. Run all cells\n",
        "3. Copy the ngrok URL to your webapp's `.env`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 1Ô∏è‚É£ Install Dependencies\n",
        "!pip install -q transformers accelerate bitsandbytes torch\n",
        "!pip install -q fastapi uvicorn pyngrok nest-asyncio\n",
        "!pip install -q pydantic\n",
        "\n",
        "print(\"‚úÖ Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 2Ô∏è‚É£ Setup ngrok (Get free token at ngrok.com)\n",
        "# Get your free auth token from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "if NGROK_AUTH_TOKEN:\n",
        "    from pyngrok import ngrok\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    print(\"‚úÖ ngrok configured!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No ngrok token - will use Colab's default tunneling\")\n",
        "    print(\"Get free token at: https://dashboard.ngrok.com/get-started/your-authtoken\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 3Ô∏è‚É£ Load HuggingFace Model (Qwen2.5-7B-Instruct)\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "\n",
        "print(f\"üîÑ Loading {MODEL_NAME}...\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
        "\n",
        "# 4-bit quantization for memory efficiency\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Model loaded! Memory: {torch.cuda.memory_allocated()/1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 4Ô∏è‚É£ Define TaxAlly Tools\n",
        "from datetime import datetime, timezone\n",
        "from typing import Dict, Any, List, Optional\n",
        "\n",
        "# Tax slabs (AY 2025-26)\n",
        "OLD_REGIME_SLABS = [\n",
        "    {\"min\": 0, \"max\": 250000, \"rate\": 0},\n",
        "    {\"min\": 250000, \"max\": 500000, \"rate\": 5},\n",
        "    {\"min\": 500000, \"max\": 1000000, \"rate\": 20},\n",
        "    {\"min\": 1000000, \"max\": float('inf'), \"rate\": 30}\n",
        "]\n",
        "\n",
        "NEW_REGIME_SLABS = [\n",
        "    {\"min\": 0, \"max\": 300000, \"rate\": 0},\n",
        "    {\"min\": 300000, \"max\": 700000, \"rate\": 5},\n",
        "    {\"min\": 700000, \"max\": 1000000, \"rate\": 10},\n",
        "    {\"min\": 1000000, \"max\": 1200000, \"rate\": 15},\n",
        "    {\"min\": 1200000, \"max\": 1500000, \"rate\": 20},\n",
        "    {\"min\": 1500000, \"max\": float('inf'), \"rate\": 30}\n",
        "]\n",
        "\n",
        "SPECIAL_STATES = ['Arunachal Pradesh', 'Assam', 'Manipur', 'Meghalaya', 'Mizoram', 'Nagaland', 'Sikkim', 'Tripura']\n",
        "\n",
        "def calculate_slab_tax(income: float, slabs: list) -> tuple:\n",
        "    remaining = income\n",
        "    total_tax = 0\n",
        "    breakdown = []\n",
        "    \n",
        "    for slab in slabs:\n",
        "        if remaining <= 0:\n",
        "            break\n",
        "        taxable = min(remaining, slab[\"max\"] - slab[\"min\"])\n",
        "        tax = taxable * slab[\"rate\"] / 100\n",
        "        if tax > 0:\n",
        "            breakdown.append({\"slab\": f\"{slab['rate']}%\", \"tax\": tax})\n",
        "        total_tax += tax\n",
        "        remaining -= taxable\n",
        "    \n",
        "    return total_tax, breakdown\n",
        "\n",
        "class TaxAllyTools:\n",
        "    @staticmethod\n",
        "    def calculate_income_tax(income: float, deductions_80c: float = 0, deductions_80d: float = 0) -> dict:\n",
        "        \"\"\"Calculate income tax with old vs new regime comparison.\"\"\"\n",
        "        std_deduction = 75000\n",
        "        \n",
        "        # Old regime\n",
        "        old_deductions = min(deductions_80c, 150000) + min(deductions_80d, 50000) + std_deduction\n",
        "        old_taxable = max(0, income - old_deductions)\n",
        "        old_tax, old_breakdown = calculate_slab_tax(old_taxable, OLD_REGIME_SLABS)\n",
        "        if old_taxable <= 500000:\n",
        "            old_tax = max(0, old_tax - 12500)\n",
        "        old_cess = old_tax * 0.04\n",
        "        old_total = old_tax + old_cess\n",
        "        \n",
        "        # New regime\n",
        "        new_taxable = max(0, income - std_deduction)\n",
        "        new_tax, new_breakdown = calculate_slab_tax(new_taxable, NEW_REGIME_SLABS)\n",
        "        if new_taxable <= 700000:\n",
        "            new_tax = max(0, new_tax - 25000)\n",
        "        new_cess = new_tax * 0.04\n",
        "        new_total = new_tax + new_cess\n",
        "        \n",
        "        savings = abs(old_total - new_total)\n",
        "        recommendation = f\"{'Old' if old_total < new_total else 'New'} Regime saves ‚Çπ{savings:,.0f}\"\n",
        "        \n",
        "        return {\n",
        "            \"old_regime\": {\"totalTax\": old_total, \"effectiveRate\": (old_total/income*100) if income > 0 else 0},\n",
        "            \"new_regime\": {\"totalTax\": new_total, \"effectiveRate\": (new_total/income*100) if income > 0 else 0},\n",
        "            \"recommendation\": recommendation\n",
        "        }\n",
        "    \n",
        "    @staticmethod\n",
        "    def check_gst_compliance(turnover: float, is_service: bool, state: str) -> dict:\n",
        "        \"\"\"Check GST registration requirement.\"\"\"\n",
        "        is_special = state in SPECIAL_STATES\n",
        "        \n",
        "        if is_service:\n",
        "            threshold = 1000000 if is_special else 2000000\n",
        "        else:\n",
        "            threshold = 2000000 if is_special else 4000000\n",
        "        \n",
        "        required = turnover > threshold\n",
        "        \n",
        "        return {\n",
        "            \"registrationRequired\": required,\n",
        "            \"threshold\": threshold,\n",
        "            \"limitDescription\": f\"‚Çπ{threshold/100000:.0f} Lakhs ({'Special' if is_special else 'Regular'} State)\",\n",
        "            \"recommendedAction\": f\"{'Register for GST immediately' if required else f'No registration needed. Headroom: ‚Çπ{(threshold-turnover)/100000:.1f}L'}\"\n",
        "        }\n",
        "    \n",
        "    @staticmethod\n",
        "    def check_presumptive(gross_receipts: float, business_type: str) -> dict:\n",
        "        \"\"\"Check 44AD/44ADA eligibility.\"\"\"\n",
        "        is_professional = business_type == \"professional\"\n",
        "        section = \"44ADA\" if is_professional else \"44AD\"\n",
        "        limit = 7500000 if is_professional else 30000000\n",
        "        \n",
        "        eligible = gross_receipts <= limit\n",
        "        \n",
        "        if is_professional:\n",
        "            deemed_income = gross_receipts * 0.50\n",
        "            explanation = f\"50% of ‚Çπ{gross_receipts:,.0f} = ‚Çπ{deemed_income:,.0f}\"\n",
        "        else:\n",
        "            deemed_income = gross_receipts * 0.06  # Assuming mostly digital\n",
        "            explanation = f\"6% of ‚Çπ{gross_receipts:,.0f} = ‚Çπ{deemed_income:,.0f}\"\n",
        "        \n",
        "        return {\n",
        "            \"section\": section,\n",
        "            \"eligible\": eligible,\n",
        "            \"deemedIncome\": deemed_income,\n",
        "            \"explanation\": explanation\n",
        "        }\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_deadlines(has_gst: bool = False) -> dict:\n",
        "        \"\"\"Get upcoming tax deadlines.\"\"\"\n",
        "        today = datetime.now()\n",
        "        fy_year = today.year if today.month >= 4 else today.year - 1\n",
        "        \n",
        "        deadlines = [\n",
        "            {\"name\": \"Advance Tax Q4\", \"date\": f\"{fy_year+1}-03-15\", \"category\": \"Income Tax\"},\n",
        "            {\"name\": \"ITR Filing\", \"date\": f\"{fy_year+1}-07-31\", \"category\": \"Income Tax\"},\n",
        "        ]\n",
        "        \n",
        "        if has_gst:\n",
        "            next_month = (today.month % 12) + 1\n",
        "            next_year = today.year + (1 if today.month == 12 else 0)\n",
        "            deadlines.append({\"name\": \"GSTR-3B\", \"date\": f\"{next_year}-{next_month:02d}-20\", \"category\": \"GST\"})\n",
        "            deadlines.append({\"name\": \"GSTR-1\", \"date\": f\"{next_year}-{next_month:02d}-11\", \"category\": \"GST\"})\n",
        "        \n",
        "        # Calculate days until\n",
        "        for d in deadlines:\n",
        "            deadline_date = datetime.strptime(d[\"date\"], \"%Y-%m-%d\")\n",
        "            d[\"daysUntil\"] = (deadline_date - today).days\n",
        "            d[\"urgency\"] = \"CRITICAL\" if d[\"daysUntil\"] <= 7 else \"WARNING\" if d[\"daysUntil\"] <= 15 else \"NORMAL\"\n",
        "        \n",
        "        return {\"upcoming_deadlines\": sorted(deadlines, key=lambda x: x[\"daysUntil\"]), \"total_count\": len(deadlines)}\n",
        "\n",
        "tools = TaxAllyTools()\n",
        "print(\"‚úÖ TaxAlly Tools initialized!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 5Ô∏è‚É£ Define LLM Chat Function\n",
        "import json\n",
        "import re\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"You are TaxAlly, an expert AI tax compliance assistant for Indian individuals and micro-businesses.\n",
        "\n",
        "You have access to these tools:\n",
        "- calculate_income_tax(income, deductions_80c, deductions_80d): Compare old vs new tax regime\n",
        "- check_gst_compliance(turnover, is_service, state): Check GST registration requirement\n",
        "- check_presumptive(gross_receipts, business_type): Check 44AD/44ADA eligibility\n",
        "- get_deadlines(has_gst): Get upcoming tax deadlines\n",
        "\n",
        "When you need to use a tool, output it in this format:\n",
        "```tool\n",
        "{\"tool\": \"tool_name\", \"params\": {\"param1\": value1}}\n",
        "```\n",
        "\n",
        "Guidelines:\n",
        "- Be precise and cite specific sections/rules\n",
        "- Always explain your reasoning\n",
        "- Flag compliance risks clearly\n",
        "- Recommend professional consultation for complex cases\n",
        "\"\"\"\n",
        "\n",
        "def generate_response(user_message: str, profile: dict = None, history: list = None) -> dict:\n",
        "    \"\"\"Generate response using the LLM with tool calling.\"\"\"\n",
        "    \n",
        "    # Build messages\n",
        "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
        "    \n",
        "    if profile:\n",
        "        profile_str = f\"\\nUser Profile: {json.dumps(profile)}\"\n",
        "        messages[0][\"content\"] += profile_str\n",
        "    \n",
        "    if history:\n",
        "        for h in history[-5:]:  # Last 5 messages\n",
        "            messages.append({\"role\": \"user\", \"content\": h.get(\"user\", \"\")})\n",
        "            messages.append({\"role\": \"assistant\", \"content\": h.get(\"assistant\", \"\")})\n",
        "    \n",
        "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "    \n",
        "    # Format for Qwen\n",
        "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "    \n",
        "    # Generate\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=1024,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    \n",
        "    response_text = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
        "    \n",
        "    # Check for tool calls\n",
        "    tool_calls = []\n",
        "    tool_pattern = r\"```tool\\n(.*?)\\n```\"\n",
        "    matches = re.findall(tool_pattern, response_text, re.DOTALL)\n",
        "    \n",
        "    for match in matches:\n",
        "        try:\n",
        "            tool_data = json.loads(match)\n",
        "            tool_name = tool_data.get(\"tool\")\n",
        "            params = tool_data.get(\"params\", {})\n",
        "            \n",
        "            # Execute tool\n",
        "            if tool_name == \"calculate_income_tax\":\n",
        "                result = tools.calculate_income_tax(**params)\n",
        "            elif tool_name == \"check_gst_compliance\":\n",
        "                result = tools.check_gst_compliance(**params)\n",
        "            elif tool_name == \"check_presumptive\":\n",
        "                result = tools.check_presumptive(**params)\n",
        "            elif tool_name == \"get_deadlines\":\n",
        "                result = tools.get_deadlines(**params)\n",
        "            else:\n",
        "                result = {\"error\": f\"Unknown tool: {tool_name}\"}\n",
        "            \n",
        "            tool_calls.append({\"tool\": tool_name, \"params\": params, \"result\": result})\n",
        "            \n",
        "            # Inject result back and regenerate if needed\n",
        "            response_text = response_text.replace(f\"```tool\\n{match}\\n```\", f\"\\n**Tool Result ({tool_name}):** {json.dumps(result)}\\n\")\n",
        "            \n",
        "        except json.JSONDecodeError:\n",
        "            continue\n",
        "    \n",
        "    return {\n",
        "        \"response\": response_text,\n",
        "        \"tool_calls\": tool_calls\n",
        "    }\n",
        "\n",
        "# Test\n",
        "test_response = generate_response(\"What is GST threshold for services in Maharashtra?\")\n",
        "print(\"Test response:\", test_response[\"response\"][:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 6Ô∏è‚É£ Create FastAPI Server\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "from typing import Optional, List, Dict, Any\n",
        "import uuid\n",
        "\n",
        "app = FastAPI(title=\"TaxAlly API\", version=\"1.0.0\")\n",
        "\n",
        "# Enable CORS for webapp\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# Request/Response models\n",
        "class ChatRequest(BaseModel):\n",
        "    message: str\n",
        "    session_id: Optional[str] = None\n",
        "    user_id: Optional[str] = None\n",
        "    profile: Optional[Dict[str, Any]] = None\n",
        "\n",
        "class ChatResponse(BaseModel):\n",
        "    response: str\n",
        "    session_id: str\n",
        "    tool_calls: List[dict] = []\n",
        "    suggestions: List[str] = []\n",
        "\n",
        "class ToolRequest(BaseModel):\n",
        "    tool: str\n",
        "    params: Dict[str, Any] = {}\n",
        "\n",
        "# In-memory session storage\n",
        "sessions = {}\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health():\n",
        "    return {\n",
        "        \"status\": \"healthy\",\n",
        "        \"model\": \"Qwen/Qwen2.5-7B-Instruct\",\n",
        "        \"gpu\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\n",
        "    }\n",
        "\n",
        "@app.post(\"/chat\", response_model=ChatResponse)\n",
        "async def chat(request: ChatRequest):\n",
        "    session_id = request.session_id or str(uuid.uuid4())\n",
        "    \n",
        "    # Get/create session history\n",
        "    history = sessions.get(session_id, [])\n",
        "    \n",
        "    # Generate response\n",
        "    result = generate_response(request.message, request.profile, history)\n",
        "    \n",
        "    # Store in history\n",
        "    history.append({\"user\": request.message, \"assistant\": result[\"response\"]})\n",
        "    sessions[session_id] = history[-10:]  # Keep last 10\n",
        "    \n",
        "    return ChatResponse(\n",
        "        response=result[\"response\"],\n",
        "        session_id=session_id,\n",
        "        tool_calls=result.get(\"tool_calls\", []),\n",
        "        suggestions=[\"Ask about GST\", \"Calculate tax\", \"Check deadlines\"]\n",
        "    )\n",
        "\n",
        "@app.get(\"/tools\")\n",
        "async def list_tools():\n",
        "    return {\n",
        "        \"tools\": [\n",
        "            {\"name\": \"calculate_income_tax\", \"description\": \"Compare old vs new tax regime\"},\n",
        "            {\"name\": \"check_gst_compliance\", \"description\": \"Check GST registration requirement\"},\n",
        "            {\"name\": \"check_presumptive\", \"description\": \"Check 44AD/44ADA eligibility\"},\n",
        "            {\"name\": \"get_deadlines\", \"description\": \"Get upcoming tax deadlines\"}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "@app.post(\"/tools/execute\")\n",
        "async def execute_tool(request: ToolRequest):\n",
        "    try:\n",
        "        if request.tool == \"calculate_income_tax\":\n",
        "            result = tools.calculate_income_tax(**request.params)\n",
        "        elif request.tool == \"check_gst_compliance\":\n",
        "            result = tools.check_gst_compliance(**request.params)\n",
        "        elif request.tool == \"check_presumptive\":\n",
        "            result = tools.check_presumptive(**request.params)\n",
        "        elif request.tool == \"get_deadlines\":\n",
        "            result = tools.get_deadlines(**request.params)\n",
        "        else:\n",
        "            raise HTTPException(status_code=400, detail=f\"Unknown tool: {request.tool}\")\n",
        "        \n",
        "        return {\"success\": True, \"tool\": request.tool, \"result\": result}\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"tool\": request.tool, \"error\": str(e)}\n",
        "\n",
        "@app.get(\"/deadlines\")\n",
        "async def get_deadlines(has_gst: bool = False):\n",
        "    return tools.get_deadlines(has_gst)\n",
        "\n",
        "print(\"‚úÖ FastAPI app created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 7Ô∏è‚É£ üöÄ Start Server with ngrok (RUN THIS!)\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"=\" * 60)\n",
        "print(\"üéâ TaxAlly Server is LIVE!\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nüåê PUBLIC URL: {public_url}\")\n",
        "print(f\"\\nüìã Copy this to your webapp's .env file:\")\n",
        "print(f\"   TAXALLY_API_URL={public_url}\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"\\nüì° Endpoints:\")\n",
        "print(f\"   GET  {public_url}/health\")\n",
        "print(f\"   POST {public_url}/chat\")\n",
        "print(f\"   GET  {public_url}/tools\")\n",
        "print(f\"   POST {public_url}/tools/execute\")\n",
        "print(f\"   GET  {public_url}/deadlines\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"\\n‚è≥ Server running... (Keep this cell running!)\")\n",
        "print(\"   Press the STOP button to shut down.\\n\")\n",
        "\n",
        "# Run server\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Webapp Configuration\n",
        "\n",
        "After running the server, update your webapp:\n",
        "\n",
        "### Server `.env` file:\n",
        "```bash\n",
        "# /Users/aditya/developer/hackathons/GFGVB/server/.env\n",
        "TAXALLY_API_URL=https://xxxx-xx-xxx-xxx-xxx.ngrok-free.app\n",
        "USE_TAXALLY_SERVER=true\n",
        "```\n",
        "\n",
        "### Test the connection:\n",
        "```bash\n",
        "curl https://your-ngrok-url/health\n",
        "```\n",
        "\n",
        "### Expected response:\n",
        "```json\n",
        "{\"status\": \"healthy\", \"model\": \"Qwen/Qwen2.5-7B-Instruct\", \"gpu\": \"Tesla T4\"}\n",
        "```"
      ]
    }
  ]
}
