{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipYfg8_Qp2Hk"
      },
      "source": [
        "# üßæ TaxAlly Production Agent - Colab Server\n",
        "\n",
        "**Production-grade agent designed for seamless frontend/backend integration**\n",
        "\n",
        "## Architecture\n",
        "- ‚úÖ Matches exact frontend/backend contracts\n",
        "- ‚úÖ Structured input/output (no hacks)\n",
        "- ‚úÖ Session management\n",
        "- ‚úÖ Same tax logic (all tools preserved)\n",
        "- ‚úÖ Better error handling\n",
        "\n",
        "## Setup\n",
        "1. Runtime ‚Üí Change runtime type ‚Üí T4 GPU\n",
        "2. Run all cells\n",
        "3. Copy ngrok URL to server/.env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyJhSZLMp2Hl",
        "outputId": "be7d06b2-cace-4593-e779-3d2bfba7a14f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ Dependencies installed!\n"
          ]
        }
      ],
      "source": [
        "#@title 1Ô∏è‚É£ Install Dependencies\n",
        "!pip install -q transformers accelerate bitsandbytes torch\n",
        "!pip install -q fastapi uvicorn pyngrok nest-asyncio\n",
        "!pip install -q pydantic\n",
        "\n",
        "print(\"‚úÖ Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVEdJqE8p2Hn",
        "outputId": "f690d8a5-cfc2-4722-c00e-e5e110426566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ngrok configured!\n"
          ]
        }
      ],
      "source": [
        "#@title 2Ô∏è‚É£ Setup ngrok\n",
        "# Get token from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"2zh80dsdTkMU8LwKIgoHTc83vM1_2SWnKGKPDMDTtPGVqGgaa\"  #@param {type:\"string\"}\n",
        "\n",
        "if NGROK_AUTH_TOKEN:\n",
        "    from pyngrok import ngrok\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    print(\"‚úÖ ngrok configured!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No ngrok token provided\")\n",
        "    print(\"Get free token at: https://dashboard.ngrok.com/get-started/your-authtoken\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "121eda80e19644018c029ba26852ffb8",
            "16637c7eef634a438b9409a290a1bd8d",
            "44f39cce859f4383b4444bfdfa68b248",
            "a9c03347679f4adc80e00614a6fb1809",
            "7c350ea5163841fb90cce966e277e715",
            "2dd4effc35ed44c080dd3fd0a4b0e143",
            "ea0aa84e77e04fcdb548d860637222c8",
            "750090f0cd614dc5a79acc054ffea772",
            "ed5eaa120f15457587ae9603ca16d074",
            "95c4be1163004796a2b04ba95305cf01",
            "27df3518c5124836882de65e250145ed"
          ]
        },
        "id": "9t57z76Yp2Hn",
        "outputId": "cf9bfa02-2957-420d-8676-94a64a58d815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Loading Qwen/Qwen2.5-7B-Instruct...\n",
            "GPU: Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "121eda80e19644018c029ba26852ffb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model loaded! Memory: 5.56 GB\n"
          ]
        }
      ],
      "source": [
        "#@title 3Ô∏è‚É£ Load Qwen2.5-7B-Instruct Model\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "\n",
        "print(f\"üîÑ Loading {MODEL_NAME}...\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
        "\n",
        "# 4-bit quantization\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Model loaded! Memory: {torch.cuda.memory_allocated()/1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkzdLqFrp2Hn",
        "outputId": "89db5c5a-182f-456b-ca28-a14c76f7ccb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ TaxAlly Tools initialized!\n"
          ]
        }
      ],
      "source": [
        "#@title 4Ô∏è‚É£ TaxAlly Tools (Same as before)\n",
        "from datetime import datetime\n",
        "from typing import Dict, Any\n",
        "\n",
        "# Tax slabs (AY 2025-26)\n",
        "OLD_REGIME_SLABS = [\n",
        "    {\"min\": 0, \"max\": 250000, \"rate\": 0},\n",
        "    {\"min\": 250000, \"max\": 500000, \"rate\": 5},\n",
        "    {\"min\": 500000, \"max\": 1000000, \"rate\": 20},\n",
        "    {\"min\": 1000000, \"max\": float('inf'), \"rate\": 30}\n",
        "]\n",
        "\n",
        "NEW_REGIME_SLABS = [\n",
        "    {\"min\": 0, \"max\": 300000, \"rate\": 0},\n",
        "    {\"min\": 300000, \"max\": 700000, \"rate\": 5},\n",
        "    {\"min\": 700000, \"max\": 1000000, \"rate\": 10},\n",
        "    {\"min\": 1000000, \"max\": 1200000, \"rate\": 15},\n",
        "    {\"min\": 1200000, \"max\": 1500000, \"rate\": 20},\n",
        "    {\"min\": 1500000, \"max\": float('inf'), \"rate\": 30}\n",
        "]\n",
        "\n",
        "SPECIAL_STATES = ['Arunachal Pradesh', 'Assam', 'Manipur', 'Meghalaya', 'Mizoram', 'Nagaland', 'Sikkim', 'Tripura']\n",
        "\n",
        "def calculate_slab_tax(income: float, slabs: list) -> tuple:\n",
        "    remaining = income\n",
        "    total_tax = 0\n",
        "    breakdown = []\n",
        "\n",
        "    for slab in slabs:\n",
        "        if remaining <= 0:\n",
        "            break\n",
        "        taxable = min(remaining, slab[\"max\"] - slab[\"min\"])\n",
        "        tax = taxable * slab[\"rate\"] / 100\n",
        "        if tax > 0:\n",
        "            breakdown.append({\"slab\": f\"{slab['rate']}%\", \"tax\": tax})\n",
        "        total_tax += tax\n",
        "        remaining -= taxable\n",
        "\n",
        "    return total_tax, breakdown\n",
        "\n",
        "class TaxAllyTools:\n",
        "    @staticmethod\n",
        "    def calculate_income_tax(income: float, deductions_80c: float = 0, deductions_80d: float = 0) -> dict:\n",
        "        \"\"\"Calculate income tax with old vs new regime comparison.\"\"\"\n",
        "        std_deduction = 75000\n",
        "\n",
        "        # Old regime\n",
        "        old_deductions = min(deductions_80c, 150000) + min(deductions_80d, 50000) + std_deduction\n",
        "        old_taxable = max(0, income - old_deductions)\n",
        "        old_tax, old_breakdown = calculate_slab_tax(old_taxable, OLD_REGIME_SLABS)\n",
        "        if old_taxable <= 500000:\n",
        "            old_tax = max(0, old_tax - 12500)\n",
        "        old_cess = old_tax * 0.04\n",
        "        old_total = old_tax + old_cess\n",
        "\n",
        "        # New regime\n",
        "        new_taxable = max(0, income - std_deduction)\n",
        "        new_tax, new_breakdown = calculate_slab_tax(new_taxable, NEW_REGIME_SLABS)\n",
        "        if new_taxable <= 700000:\n",
        "            new_tax = max(0, new_tax - 25000)\n",
        "        new_cess = new_tax * 0.04\n",
        "        new_total = new_tax + new_cess\n",
        "\n",
        "        savings = abs(old_total - new_total)\n",
        "        recommendation = f\"{'Old' if old_total < new_total else 'New'} Regime saves ‚Çπ{savings:,.0f}\"\n",
        "\n",
        "        return {\n",
        "            \"old_regime\": {\"totalTax\": old_total, \"effectiveRate\": (old_total/income*100) if income > 0 else 0},\n",
        "            \"new_regime\": {\"totalTax\": new_total, \"effectiveRate\": (new_total/income*100) if income > 0 else 0},\n",
        "            \"recommendation\": recommendation\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def check_gst_compliance(turnover: float, is_service: bool, state: str) -> dict:\n",
        "        \"\"\"Check GST registration requirement.\"\"\"\n",
        "        is_special = state in SPECIAL_STATES\n",
        "\n",
        "        if is_service:\n",
        "            threshold = 1000000 if is_special else 2000000\n",
        "        else:\n",
        "            threshold = 2000000 if is_special else 4000000\n",
        "\n",
        "        required = turnover > threshold\n",
        "\n",
        "        return {\n",
        "            \"registrationRequired\": required,\n",
        "            \"threshold\": threshold,\n",
        "            \"limitDescription\": f\"‚Çπ{threshold/100000:.0f} Lakhs ({'Special' if is_special else 'Regular'} State)\",\n",
        "            \"recommendedAction\": f\"{'Register for GST immediately' if required else f'No registration needed. Headroom: ‚Çπ{(threshold-turnover)/100000:.1f}L'}\"\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def check_presumptive(gross_receipts: float, business_type: str) -> dict:\n",
        "        \"\"\"Check 44AD/44ADA eligibility.\"\"\"\n",
        "        is_professional = business_type == \"professional\"\n",
        "        section = \"44ADA\" if is_professional else \"44AD\"\n",
        "        limit = 7500000 if is_professional else 30000000\n",
        "\n",
        "        eligible = gross_receipts <= limit\n",
        "\n",
        "        if is_professional:\n",
        "            deemed_income = gross_receipts * 0.50\n",
        "            explanation = f\"50% of ‚Çπ{gross_receipts:,.0f} = ‚Çπ{deemed_income:,.0f}\"\n",
        "        else:\n",
        "            deemed_income = gross_receipts * 0.06\n",
        "            explanation = f\"6% of ‚Çπ{gross_receipts:,.0f} = ‚Çπ{deemed_income:,.0f}\"\n",
        "\n",
        "        return {\n",
        "            \"section\": section,\n",
        "            \"eligible\": eligible,\n",
        "            \"deemedIncome\": deemed_income,\n",
        "            \"explanation\": explanation\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def get_deadlines(has_gst: bool = False) -> dict:\n",
        "        \"\"\"Get upcoming tax deadlines.\"\"\"\n",
        "        today = datetime.now()\n",
        "        fy_year = today.year if today.month >= 4 else today.year - 1\n",
        "\n",
        "        deadlines = [\n",
        "            {\"name\": \"Advance Tax Q4\", \"date\": f\"{fy_year+1}-03-15\", \"category\": \"Income Tax\"},\n",
        "            {\"name\": \"ITR Filing\", \"date\": f\"{fy_year+1}-07-31\", \"category\": \"Income Tax\"},\n",
        "        ]\n",
        "\n",
        "        if has_gst:\n",
        "            next_month = (today.month % 12) + 1\n",
        "            next_year = today.year + (1 if today.month == 12 else 0)\n",
        "            deadlines.append({\"name\": \"GSTR-3B\", \"date\": f\"{next_year}-{next_month:02d}-20\", \"category\": \"GST\"})\n",
        "            deadlines.append({\"name\": \"GSTR-1\", \"date\": f\"{next_year}-{next_month:02d}-11\", \"category\": \"GST\"})\n",
        "\n",
        "        for d in deadlines:\n",
        "            deadline_date = datetime.strptime(d[\"date\"], \"%Y-%m-%d\")\n",
        "            d[\"daysUntil\"] = (deadline_date - today).days\n",
        "            d[\"urgency\"] = \"CRITICAL\" if d[\"daysUntil\"] <= 7 else \"WARNING\" if d[\"daysUntil\"] <= 15 else \"NORMAL\"\n",
        "\n",
        "        return {\"upcoming_deadlines\": sorted(deadlines, key=lambda x: x[\"daysUntil\"]), \"total_count\": len(deadlines)}\n",
        "\n",
        "tools = TaxAllyTools()\n",
        "print(\"‚úÖ TaxAlly Tools initialized!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O63C8BgFp2Ho",
        "outputId": "db48e913-9aa9-44fe-9917-c403c3ff22f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Agent core ready!\n"
          ]
        }
      ],
      "source": [
        "#@title 5Ô∏è‚É£ Agent Core - LLM Response Generator\n",
        "import json\n",
        "import re\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"You are TaxAlly, an expert AI tax compliance assistant for Indian individuals and micro-businesses.\n",
        "\n",
        "You have access to these tools:\n",
        "- calculate_income_tax(income, deductions_80c, deductions_80d): Compare old vs new tax regime\n",
        "- check_gst_compliance(turnover, is_service, state): Check GST registration requirement\n",
        "- check_presumptive(gross_receipts, business_type): Check 44AD/44ADA eligibility\n",
        "- get_deadlines(has_gst): Get upcoming tax deadlines\n",
        "\n",
        "When you need to use a tool, output it in this format:\n",
        "```tool\n",
        "{\"tool\": \"tool_name\", \"params\": {\"param1\": value1}}\n",
        "```\n",
        "\n",
        "Guidelines:\n",
        "- Be precise and cite specific sections/rules\n",
        "- Always explain your reasoning\n",
        "- Flag compliance risks clearly\n",
        "- Recommend professional consultation for complex cases\n",
        "\"\"\"\n",
        "\n",
        "def generate_response(user_message: str, profile: dict = None, history: list = None) -> dict:\n",
        "    \"\"\"Generate response with tool calling support.\"\"\"\n",
        "\n",
        "    # Build messages\n",
        "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
        "\n",
        "    if profile:\n",
        "        profile_str = f\"\\nUser Profile: {json.dumps(profile)}\"\n",
        "        messages[0][\"content\"] += profile_str\n",
        "\n",
        "    if history:\n",
        "        for h in history[-5:]:  # Last 5 exchanges\n",
        "            user_content = h.get(\"user\", \"\")\n",
        "            assistant_content = h.get(\"assistant\", \"\")\n",
        "            # Ensure strings (handle dict if passed)\n",
        "            if isinstance(user_content, dict):\n",
        "                user_content = json.dumps(user_content)\n",
        "            if isinstance(assistant_content, dict):\n",
        "                assistant_content = json.dumps(assistant_content)\n",
        "            messages.append({\"role\": \"user\", \"content\": str(user_content)})\n",
        "            messages.append({\"role\": \"assistant\", \"content\": str(assistant_content)})\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": str(user_message)})\n",
        "\n",
        "    # Format for Qwen\n",
        "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # Generate\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=1024,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    response_text = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "    # Execute tool calls\n",
        "    tool_calls = []\n",
        "    tool_pattern = r\"```tool\\n(.*?)\\n```\"\n",
        "    matches = re.findall(tool_pattern, response_text, re.DOTALL)\n",
        "\n",
        "    for match in matches:\n",
        "        try:\n",
        "            tool_data = json.loads(match)\n",
        "            tool_name = tool_data.get(\"tool\")\n",
        "            params = tool_data.get(\"params\", {})\n",
        "\n",
        "            # Execute tool\n",
        "            if tool_name == \"calculate_income_tax\":\n",
        "                result = tools.calculate_income_tax(**params)\n",
        "            elif tool_name == \"check_gst_compliance\":\n",
        "                result = tools.check_gst_compliance(**params)\n",
        "            elif tool_name == \"check_presumptive\":\n",
        "                result = tools.check_presumptive(**params)\n",
        "            elif tool_name == \"get_deadlines\":\n",
        "                result = tools.get_deadlines(**params)\n",
        "            else:\n",
        "                result = {\"error\": f\"Unknown tool: {tool_name}\"}\n",
        "\n",
        "            tool_calls.append({\"tool\": tool_name, \"params\": params, \"result\": result})\n",
        "            # Inject result back into response\n",
        "            response_text = response_text.replace(\n",
        "                f\"```tool\\n{match}\\n```\",\n",
        "                f\"\\n**Tool Result ({tool_name}):** {json.dumps(result)}\\n\"\n",
        "            )\n",
        "        except json.JSONDecodeError:\n",
        "            continue\n",
        "\n",
        "    return {\n",
        "        \"response\": response_text,\n",
        "        \"tool_calls\": tool_calls\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Agent core ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX3oajSrp2Ho",
        "outputId": "723a7430-ffd2-4f94-8209-73cd20915355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ FastAPI app created!\n"
          ]
        }
      ],
      "source": [
        "#@title 6Ô∏è‚É£ FastAPI Server - Matches Backend Contracts\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "from typing import Optional, List, Dict, Any\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "\n",
        "app = FastAPI(title=\"TaxAlly API\", version=\"2.0.0\")\n",
        "\n",
        "# CORS for webapp\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# REQUEST/RESPONSE MODELS (Match backend contracts)\n",
        "class ChatRequest(BaseModel):\n",
        "    message: str\n",
        "    session_id: Optional[str] = None\n",
        "    user_id: Optional[str] = None\n",
        "    profile: Optional[Dict[str, Any]] = None\n",
        "\n",
        "class ChatResponse(BaseModel):\n",
        "    response: str\n",
        "    session_id: str\n",
        "    tool_calls: List[dict] = []\n",
        "    suggestions: List[str] = []\n",
        "\n",
        "class ToolRequest(BaseModel):\n",
        "    tool: str\n",
        "    params: Dict[str, Any] = {}\n",
        "\n",
        "# SESSION STORAGE\n",
        "sessions: Dict[str, List[Dict]] = {}\n",
        "\n",
        "# ENDPOINTS\n",
        "@app.get(\"/health\")\n",
        "async def health():\n",
        "    \"\"\"Health check - matches backend's TaxAllyClient.getHealth() expectation\"\"\"\n",
        "    return {\n",
        "        \"status\": \"healthy\",\n",
        "        \"version\": \"2.0.0\",\n",
        "        \"model\": \"Qwen/Qwen2.5-7B-Instruct\",\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "@app.post(\"/chat\", response_model=ChatResponse)\n",
        "async def chat(request: ChatRequest):\n",
        "    \"\"\"Chat endpoint - matches backend's TaxAllyClient.chat() contract\"\"\"\n",
        "    session_id = request.session_id or str(uuid.uuid4())\n",
        "\n",
        "    # Get/create session history\n",
        "    history = sessions.get(session_id, [])\n",
        "\n",
        "    # Generate response\n",
        "    result = generate_response(request.message, request.profile, history)\n",
        "\n",
        "    # Update history\n",
        "    history.append({\n",
        "        \"user\": request.message,\n",
        "        \"assistant\": result[\"response\"]\n",
        "    })\n",
        "    sessions[session_id] = history[-10:]  # Keep last 10\n",
        "\n",
        "    return ChatResponse(\n",
        "        response=result[\"response\"],\n",
        "        session_id=session_id,\n",
        "        tool_calls=result.get(\"tool_calls\", []),\n",
        "        suggestions=[\"Ask about GST\", \"Calculate tax\", \"Check deadlines\"]\n",
        "    )\n",
        "\n",
        "@app.get(\"/tools\")\n",
        "async def list_tools():\n",
        "    \"\"\"List available tools\"\"\"\n",
        "    return {\n",
        "        \"tools\": [\n",
        "            {\n",
        "                \"name\": \"calculate_income_tax\",\n",
        "                \"description\": \"Compare old vs new tax regime\"\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"check_gst_compliance\",\n",
        "                \"description\": \"Check GST registration requirement\"\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"check_presumptive\",\n",
        "                \"description\": \"Check 44AD/44ADA eligibility\"\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"get_deadlines\",\n",
        "                \"description\": \"Get upcoming tax deadlines\"\n",
        "            }\n",
        "        ],\n",
        "        \"count\": 4\n",
        "    }\n",
        "\n",
        "@app.post(\"/tools/execute\")\n",
        "async def execute_tool(request: ToolRequest):\n",
        "    \"\"\"Execute a specific tool - matches backend's TaxAllyClient.executeTool() contract\"\"\"\n",
        "    try:\n",
        "        if request.tool == \"calculate_income_tax\":\n",
        "            result = tools.calculate_income_tax(**request.params)\n",
        "        elif request.tool == \"check_gst_compliance\":\n",
        "            result = tools.check_gst_compliance(**request.params)\n",
        "        elif request.tool == \"check_presumptive\":\n",
        "            result = tools.check_presumptive(**request.params)\n",
        "        elif request.tool == \"get_deadlines\":\n",
        "            result = tools.get_deadlines(**request.params)\n",
        "        else:\n",
        "            raise HTTPException(\n",
        "                status_code=400,\n",
        "                detail=f\"Unknown tool: {request.tool}\"\n",
        "            )\n",
        "\n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"tool\": request.tool,\n",
        "            \"result\": result\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"tool\": request.tool,\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "@app.get(\"/deadlines\")\n",
        "async def get_deadlines(has_gst: bool = False):\n",
        "    \"\"\"Get upcoming deadlines\"\"\"\n",
        "    return tools.get_deadlines(has_gst)\n",
        "\n",
        "print(\"‚úÖ FastAPI app created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS8aVUl3p2Ho",
        "outputId": "b5c4b1f9-3d9c-4cb8-b8aa-88b0c09079b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Killed processes on port 8000: \n",
            "‚úÖ Closed ngrok tunnels\n",
            "\n",
            "‚úÖ Cleanup complete! Wait 2 seconds before running cell 8...\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import signal\n",
        "\n",
        "# Kill all processes on port 8000\n",
        "try:\n",
        "    result = subprocess.run(\n",
        "        ['fuser', '-k', '8000/tcp'],\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "    print(f\"‚úÖ Killed processes on port 8000: {result.stdout}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ÑπÔ∏è fuser command failed: {e}\")\n",
        "\n",
        "# Alternative: use lsof and kill\n",
        "try:\n",
        "    result = subprocess.run(\n",
        "        ['lsof', '-ti:8000'],\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "    pids = result.stdout.strip().split('\\n')\n",
        "    for pid in pids:\n",
        "        if pid:\n",
        "            try:\n",
        "                os.kill(int(pid), signal.SIGKILL)\n",
        "                print(f\"‚úÖ Killed process {pid}\")\n",
        "            except:\n",
        "                pass\n",
        "except Exception as e:\n",
        "    print(f\"‚ÑπÔ∏è lsof command not available: {e}\")\n",
        "\n",
        "# Close ngrok tunnels\n",
        "try:\n",
        "    ngrok.kill()\n",
        "    print(\"‚úÖ Closed ngrok tunnels\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ÑπÔ∏è No ngrok tunnels to close: {e}\")\n",
        "\n",
        "print(\"\\n‚úÖ Cleanup complete! Wait 2 seconds before running cell 8...\")\n",
        "import time\n",
        "time.sleep(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCM8B5lGp2Hp",
        "outputId": "0b59c93e-a8cf-440c-fb43-00607327375d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üéâ TaxAlly Server is LIVE!\n",
            "============================================================\n",
            "\n",
            "üåê PUBLIC URL: https://5f4b05fbe39c.ngrok-free.app\n",
            "\n",
            "üìã Add this to your webapp server/.env:\n",
            "\n",
            "   TAXALLY_API_URL=https://5f4b05fbe39c.ngrok-free.app\n",
            "   USE_TAXALLY_SERVER=true\n",
            "\n",
            "============================================================\n",
            "\n",
            "üß™ Test it: https://5f4b05fbe39c.ngrok-free.app/health\n",
            "\n",
            "============================================================\n",
            "\n",
            "‚è≥ Server running... (Keep this cell running!)\n",
            "   Press STOP button to shut down.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [10240]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     103.233.93.167:0 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     103.233.93.167:0 - \"POST /chat HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "#@title 8Ô∏è‚É£ üöÄ Start Server (RUN THIS!)\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Start ngrok tunnel\n",
        "tunnel = ngrok.connect(8000)\n",
        "public_url = tunnel.public_url\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üéâ TaxAlly Server is LIVE!\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nüåê PUBLIC URL: {public_url}\")\n",
        "print(f\"\\nüìã Add this to your webapp server/.env:\")\n",
        "print(f\"\\n   TAXALLY_API_URL={public_url}\")\n",
        "print(f\"   USE_TAXALLY_SERVER=true\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"\\nüß™ Test it: {public_url}/health\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"\\n‚è≥ Server running... (Keep this cell running!)\")\n",
        "print(\"   Press STOP button to shut down.\\n\")\n",
        "\n",
        "# Run server with Colab's event loop\n",
        "config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "server = uvicorn.Server(config)\n",
        "await server.serve()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "121eda80e19644018c029ba26852ffb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16637c7eef634a438b9409a290a1bd8d",
              "IPY_MODEL_44f39cce859f4383b4444bfdfa68b248",
              "IPY_MODEL_a9c03347679f4adc80e00614a6fb1809"
            ],
            "layout": "IPY_MODEL_7c350ea5163841fb90cce966e277e715"
          }
        },
        "16637c7eef634a438b9409a290a1bd8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dd4effc35ed44c080dd3fd0a4b0e143",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ea0aa84e77e04fcdb548d860637222c8",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "44f39cce859f4383b4444bfdfa68b248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_750090f0cd614dc5a79acc054ffea772",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed5eaa120f15457587ae9603ca16d074",
            "value": 4
          }
        },
        "a9c03347679f4adc80e00614a6fb1809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95c4be1163004796a2b04ba95305cf01",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_27df3518c5124836882de65e250145ed",
            "value": "‚Äá4/4‚Äá[01:16&lt;00:00,‚Äá19.39s/it]"
          }
        },
        "7c350ea5163841fb90cce966e277e715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dd4effc35ed44c080dd3fd0a4b0e143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea0aa84e77e04fcdb548d860637222c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "750090f0cd614dc5a79acc054ffea772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed5eaa120f15457587ae9603ca16d074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95c4be1163004796a2b04ba95305cf01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27df3518c5124836882de65e250145ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}